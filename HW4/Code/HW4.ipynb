{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import csv\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "import pyspark.sql.functions \n",
    "from pyspark.sql import Row\n",
    "from collections import OrderedDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing data from sgm file\n",
    "\n",
    "from bs4 import BeautifulSoup,SoupStrainer\n",
    "\n",
    "\n",
    "def readData(fileName):\n",
    "    \n",
    "    data = ''\n",
    "    f = open(fileName, 'rb')\n",
    "    soup = BeautifulSoup(f, 'html.parser')\n",
    "    # get body content\n",
    "    contents = soup.findAll('body')\n",
    "    \n",
    "    return contents\n",
    "\n",
    "# parsing data from sgm file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start count word Frequency\n",
      "file  0  done\n",
      "file  1  done\n",
      "file  2  done\n",
      "file  3  done\n",
      "file  4  done\n",
      "file  5  done\n",
      "file  6  done\n",
      "file  7  done\n",
      "file  8  done\n",
      "file  9  done\n",
      "file  10  done\n",
      "file  11  done\n",
      "file  12  done\n",
      "file  13  done\n",
      "file  14  done\n",
      "file  15  done\n",
      "file  16  done\n",
      "file  17  done\n",
      "file  18  done\n",
      "file  19  done\n",
      "file  20  done\n",
      "file  21  done\n",
      "Count word Frequency done\n",
      "\n",
      "Total body number: 1855\n",
      "Total word number: 45595\n",
      "Count word Frequency took: 41.23s\n"
     ]
    }
   ],
   "source": [
    "# Q1\n",
    "\n",
    "# ==== initial setting ====\n",
    "sTime = time.time()\n",
    "file = [\"000\",\"001\",\"002\",\"003\",\"004\",\"005\",\"006\",\"007\",\"008\",\"009\",\"010\",\"011\",\"012\",\"013\",\"014\",\"015\",\"016\",\"017\",\"018\",\"019\",\"020\",\"021\"]\n",
    "bodyLen, shingleLen = 0, 0\n",
    "# storage for term\n",
    "wordSet = set()\n",
    "# storage for term Frequency\n",
    "wordList = []\n",
    "# ==== initial setting ====\n",
    "\n",
    "# process all data set\n",
    "print(\"Start count word Frequency\")\n",
    "for i in range(len(file)):\n",
    "    fileName = \"/home/ethan/pythonwork/ipynotebook/HW4/Data/reut2-\"\n",
    "    fileName = fileName + file[i] + \".sgm\"\n",
    "    # read body content from each file\n",
    "    data = readData(fileName)\n",
    "    # retrival all body content\n",
    "    for content in data:\n",
    "        if i < 2:\n",
    "            bodyLen +=1\n",
    "        # split one body content by \\n\n",
    "        for d in content.get_text().split(\"\\n\"):\n",
    "            # remove header space and footer space\n",
    "            sentence = d.strip()\n",
    "            # regular expresisson\n",
    "            pat = '[a-zA-Z]+'\n",
    "            reContent = re.findall(pat, sentence)\n",
    "            # select one word on each time\n",
    "            for ind in range(len(reContent)):\n",
    "                # add word\n",
    "                wordSet.add(reContent[ind])\n",
    "    print(\"file \", i, \" done\")\n",
    "\n",
    "# for speed up word count matrix\n",
    "for w in wordSet:\n",
    "    wordList.append(w)\n",
    "wordList.sort()\n",
    "# release memory\n",
    "del wordSet\n",
    "wordLen = len(wordList)\n",
    "\n",
    "print(\"Count word Frequency done\\n\")\n",
    "print(\"Total body number: %d\" % bodyLen)\n",
    "print(\"Total word number: %d\" % wordLen)\n",
    "print(\"Count word Frequency took: %.2fs\" % (time.time()-sTime))\n",
    "\n",
    "# Q1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start calculate word Frequency matrix\n",
      "/home/ethan/pythonwork/ipynotebook/HW3/Data/reut2-000.sgm start!\n",
      "100  done!\n",
      "200  done!\n",
      "300  done!\n",
      "400  done!\n",
      "500  done!\n",
      "600  done!\n",
      "700  done!\n",
      "800  done!\n",
      "900  done!\n",
      "/home/ethan/pythonwork/ipynotebook/HW3/Data/reut2-001.sgm start!\n",
      "100  done!\n",
      "200  done!\n",
      "300  done!\n",
      "400  done!\n",
      "500  done!\n",
      "600  done!\n",
      "700  done!\n",
      "800  done!\n",
      "900  done!\n",
      "Calculate word Frequency matrix done\n",
      "total Word num 138615\n",
      "total match num 138615\n",
      "Calculate word Frequency matrix took 306.47s\n",
      "Save word Frequency matrix took 78.16\n"
     ]
    }
   ],
   "source": [
    "# Q1\n",
    "\n",
    "# ==== initial setting ====\n",
    "\n",
    "sTime = time.time()\n",
    "file = [\"000\",\"001\",\"002\",\"003\",\"004\",\"005\",\"006\",\"007\",\"008\",\"009\",\"010\",\"011\",\"012\",\"013\",\"014\",\"015\",\"016\",\"017\",\"018\",\"019\",\"020\",\"021\"]\n",
    "matchNum = 0\n",
    "col = 0\n",
    "pat = '[a-zA-Z]+'\n",
    "matrix = np.zeros((wordLen,bodyLen), int)\n",
    "totalWord = 0\n",
    "# ==== initial setting ====\n",
    "\n",
    "# process specify document\n",
    "print(\"Start calculate word Frequency matrix\")\n",
    "for i in range(2):\n",
    "    fileName = \"/home/ethan/pythonwork/ipynotebook/HW3/Data/reut2-\"\n",
    "    fileName = fileName + file[i] + \".sgm\"\n",
    "    print(fileName +\" start!\")\n",
    "    # read body content from each file\n",
    "    data = readData(fileName)\n",
    "    contInd = 0\n",
    "    for content in data:\n",
    "        # save total term frequency on one body content\n",
    "        bContWordDict = {}\n",
    "        # split one body content by \\n\n",
    "        for d in content.get_text().split(\"\\n\"):\n",
    "            # remove header space and footer space\n",
    "            sentence = d.strip()\n",
    "            # regular expresisson\n",
    "            reContent = re.findall(pat, sentence)\n",
    "            # select one word on each time\n",
    "            for r in range(len(reContent)):\n",
    "                if reContent[r] not in bContWordDict:\n",
    "                    bContWordDict[reContent[r]] = 1\n",
    "                else:\n",
    "                    bContWordDict[reContent[r]] +=1\n",
    "        # sort result in alphabetical order\n",
    "        orderRes = OrderedDict(sorted(bContWordDict.items(), key=lambda x: x[0]))\n",
    "        totalWord += len(orderRes)\n",
    "        # process all term frequency on each body content\n",
    "        row = 0\n",
    "        for w in range(wordLen):\n",
    "            try:\n",
    "                wordWithCount = list(orderRes.items())[row]\n",
    "            except IndexError:\n",
    "                print(row)\n",
    "            # find out term appeared location, then append value to matrix\n",
    "            if wordWithCount[0] == wordList[w]:\n",
    "                matrix[w][col] = wordWithCount[1]\n",
    "                matchNum += 1\n",
    "                row +=1\n",
    "            # when visit all term on one body content then break this loop\n",
    "            if row == len(orderRes):\n",
    "                break\n",
    "        col +=1\n",
    "        contInd +=1\n",
    "        if contInd %100 == 0:\n",
    "            print(contInd, \" done!\")\n",
    "        \n",
    "print(\"Calculate word Frequency matrix done\")             \n",
    "print(\"total Word num %d\" % totalWord)\n",
    "print(\"total match num %d\" % matchNum)\n",
    "print(\"Calculate word Frequency matrix took %.2fs\" % (time.time()-sTime))\n",
    "\n",
    "# save Q1 Result\n",
    "sTime = time.time()\n",
    "np.savetxt(\"Q1_Result.csv\", matrix, delimiter=\",\")\n",
    "print(\"Save word Frequency matrix took %.2f\" % (time.time()-sTime))\n",
    "\n",
    "\n",
    "\n",
    "# Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Q2\n",
    "\n",
    "# # ==== initial setting ====\n",
    "\n",
    "# sTime = time.time()\n",
    "# index = 0\n",
    "# flag = 0\n",
    "# minHash = np.zeros(bodyLen,int)\n",
    "# idx = np.full(shingleLen, False, dtype=bool)\n",
    "# curNum = 0\n",
    "# ind = 0\n",
    "# mod = 10\n",
    "\n",
    "# # ==== initial setting ====\n",
    "\n",
    "# print(\"Start process minHash!\")\n",
    "# while index < shingleLen and flag < bodyLen:\n",
    "#     curNum = ind\n",
    "#     index +=1\n",
    "#     if(curNum + mod)< shingleLen:\n",
    "#         ind = curNum + mod\n",
    "#     else:\n",
    "#         ind = (curNum + mod) % shingleLen\n",
    "#     while idx[ind] == True:\n",
    "#         ind += 1\n",
    "#     idx[ind] = True\n",
    "#     for c in range(bodyLen):\n",
    "#         if matrix[ind][c] == True:\n",
    "#             if minHash[c] == 0:\n",
    "#                 minHash[c] = index\n",
    "#                 flag +=1\n",
    "#     if index % 2000 ==0:\n",
    "#         print(\"flag \",flag, \" done!\")\n",
    "#         print(\"index \", index, \" done!\")\n",
    "        \n",
    "# print(\"Process minHash done!\")\n",
    "# print(\"MinHash calculate took %.2f\" % (time.time()-sTime))\n",
    "\n",
    "# # save Q2 Result\n",
    "# sTime = time.time()\n",
    "# np.savetxt(\"Q2_Result.csv\", minHash, delimiter=\",\")\n",
    "# print(\"Save minHash matrix took %.2fs\" % (time.time()-sTime))\n",
    "\n",
    "\n",
    "# # Q2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import OrderedDict\n",
    "\n",
    "# s = set()\n",
    "\n",
    "# s.add(\"1\")\n",
    "# s.add(\"2\")\n",
    "# s.add(\"3\")\n",
    "# s.add(\"b\")\n",
    "# s.add(\"ac\")\n",
    "# s.add(\"ed\")\n",
    "# s.add(\"a\")\n",
    "# #print(s)\n",
    "\n",
    "# l = []\n",
    "# for i in s:\n",
    "#     l.append(i)   \n",
    "# l.sort()\n",
    "\n",
    "# #print(l)\n",
    "\n",
    "\n",
    "# d = {}\n",
    "# d[\"b\"] = 123\n",
    "# d[\"ac\"] = 45\n",
    "# d[\"ed\"] = 66\n",
    "# d[\"a\"] = 777\n",
    "\n",
    "\n",
    "# ans = OrderedDict(sorted(d.items(), key=lambda x: x[0]))\n",
    "\n",
    "\n",
    "# print(ans)\n",
    "# print(l)\n",
    "\n",
    "# row = 0\n",
    "# for i in l:\n",
    "\t\n",
    "# \tasd = list(ans.items())[row]\n",
    "# \tprint(asd[0],\" \", i)\n",
    "\t\n",
    "# \tif asd[0] == i:\n",
    "# \t\tprint(i)\n",
    "# \t\trow+=1\n",
    "# \tprint(\"row \", row)\n",
    "# \tif row == len(ans)-1:\n",
    "# \t\tprint(\"HI\")\n",
    "# \t\tbreak\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
